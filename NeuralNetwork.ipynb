{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Model\n",
    "\n",
    "Use 1D-KNN\n",
    "\n",
    "Note: This code have to be run after preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras import regularizers\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.utils import class_weight\n",
    "from keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = pickle.load(open(\"./trainset.p\",'rb'))\n",
    "testset = pickle.load(open(\"./testset.p\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R_interval_mean</th>\n",
       "      <th>R_interval_sd</th>\n",
       "      <th>age</th>\n",
       "      <th>annotation</th>\n",
       "      <th>gender</th>\n",
       "      <th>id</th>\n",
       "      <th>lead</th>\n",
       "      <th>p2p_mean</th>\n",
       "      <th>p2p_std</th>\n",
       "      <th>peak</th>\n",
       "      <th>strip</th>\n",
       "      <th>p2p_diff_form_norm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stripPVC</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>937</td>\n",
       "      <td>937</td>\n",
       "      <td>937</td>\n",
       "      <td>937</td>\n",
       "      <td>937</td>\n",
       "      <td>937</td>\n",
       "      <td>937</td>\n",
       "      <td>937</td>\n",
       "      <td>937</td>\n",
       "      <td>937</td>\n",
       "      <td>937</td>\n",
       "      <td>937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>674</td>\n",
       "      <td>674</td>\n",
       "      <td>674</td>\n",
       "      <td>674</td>\n",
       "      <td>674</td>\n",
       "      <td>674</td>\n",
       "      <td>674</td>\n",
       "      <td>674</td>\n",
       "      <td>674</td>\n",
       "      <td>674</td>\n",
       "      <td>674</td>\n",
       "      <td>674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          R_interval_mean  R_interval_sd  age  annotation  gender   id  lead  \\\n",
       "stripPVC                                                                       \n",
       "False                 937            937  937         937     937  937   937   \n",
       "True                  674            674  674         674     674  674   674   \n",
       "\n",
       "          p2p_mean  p2p_std  peak  strip  p2p_diff_form_norm  \n",
       "stripPVC                                                      \n",
       "False          937      937   937    937                 937  \n",
       "True           674      674   674    674                 674  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USE_KFOLD = True\n",
    "testset.groupby('stripPVC').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = trainset['strip']\n",
    "ytrain = [i == True for i in trainset['stripPVC']]\n",
    "xtest = testset['strip']\n",
    "ytest = [i == True for i in testset['stripPVC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2864, 3600, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert\n",
    "\n",
    "xtrain = np.stack(xtrain)\n",
    "xtrain = np.reshape(xtrain, (xtrain.shape[0], xtrain.shape[1], 1))\n",
    "xtest = np.stack(xtest)\n",
    "xtest = np.reshape(xtest, (xtest.shape[0], xtest.shape[1], 1))\n",
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())\n",
    "def CNN_2(input_shape, blocks = 2, dropout = 0, regularization = 0.001, kernel_size = 16):  \n",
    "    classifier = Sequential()\n",
    "    classifier.add(Conv1D(filters = 100, kernel_size = kernel_size, activation = 'relu', input_shape = (input_shape, 1)))\n",
    "    classifier.add(Dropout(dropout))\n",
    "    classifier.add(Conv1D(filters = 160, kernel_size = kernel_size, activation = 'relu'))\n",
    "    classifier.add(MaxPooling1D(pool_size = 2))\n",
    "    classifier.add(LeakyReLU())\n",
    "    classifier.add(LeakyReLU())\n",
    "    classifier.add(Dropout(dropout))\n",
    "    classifier.add(GlobalAveragePooling1D())\n",
    "    classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "    \n",
    " \n",
    "    \n",
    "    classifier.compile(optimizer = 'adam',\n",
    "                       loss = 'binary_crossentropy',\n",
    "                       metrics = [sensitivity,specificity,'accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NUMBER = '1'\n",
    "MODEL = CNN_2\n",
    "N_SPLITS = 5\n",
    "BATCH_SIZE = 10\n",
    "EPOCHS = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2291 samples, validate on 573 samples\n",
      "Epoch 1/10\n",
      "2291/2291 [==============================] - 209s 91ms/step - loss: 0.6842 - sensitivity: 0.8799 - specificity: 0.1046 - acc: 0.5133 - val_loss: 0.6373 - val_sensitivity: 0.9599 - val_specificity: 0.0257 - val_acc: 0.7225\n",
      "Epoch 2/10\n",
      "2291/2291 [==============================] - 190s 83ms/step - loss: 0.6560 - sensitivity: 0.7494 - specificity: 0.3639 - acc: 0.5749 - val_loss: 0.7144 - val_sensitivity: 0.4075 - val_specificity: 0.3628 - val_acc: 0.4538\n",
      "Epoch 3/10\n",
      "2291/2291 [==============================] - 212s 92ms/step - loss: 0.6398 - sensitivity: 0.6668 - specificity: 0.5418 - acc: 0.6102 - val_loss: 0.5527 - val_sensitivity: 0.8290 - val_specificity: 0.2422 - val_acc: 0.7417\n",
      "Epoch 4/10\n",
      "2291/2291 [==============================] - 211s 92ms/step - loss: 0.6078 - sensitivity: 0.6937 - specificity: 0.6100 - acc: 0.6499 - val_loss: 0.5195 - val_sensitivity: 0.9350 - val_specificity: 0.0816 - val_acc: 0.7365\n",
      "Epoch 5/10\n",
      "2291/2291 [==============================] - 210s 91ms/step - loss: 0.5857 - sensitivity: 0.6685 - specificity: 0.6839 - acc: 0.6735 - val_loss: 0.5178 - val_sensitivity: 0.8353 - val_specificity: 0.1659 - val_acc: 0.6894\n",
      "Epoch 6/10\n",
      "2291/2291 [==============================] - 193s 84ms/step - loss: 0.5639 - sensitivity: 0.6873 - specificity: 0.7675 - acc: 0.7180 - val_loss: 0.4539 - val_sensitivity: 0.9091 - val_specificity: 0.1912 - val_acc: 0.7801\n",
      "Epoch 7/10\n",
      "2291/2291 [==============================] - 198s 86ms/step - loss: 0.5518 - sensitivity: 0.7036 - specificity: 0.7538 - acc: 0.7302 - val_loss: 0.5454 - val_sensitivity: 0.6845 - val_specificity: 0.4432 - val_acc: 0.7155\n",
      "Epoch 8/10\n",
      "2291/2291 [==============================] - 202s 88ms/step - loss: 0.5397 - sensitivity: 0.7163 - specificity: 0.7757 - acc: 0.7447 - val_loss: 0.5588 - val_sensitivity: 0.6635 - val_specificity: 0.4476 - val_acc: 0.7016\n",
      "Epoch 9/10\n",
      "2291/2291 [==============================] - 198s 86ms/step - loss: 0.5252 - sensitivity: 0.7320 - specificity: 0.7775 - acc: 0.7512 - val_loss: 0.6288 - val_sensitivity: 0.6366 - val_specificity: 0.3732 - val_acc: 0.6195\n",
      "Epoch 10/10\n",
      "2291/2291 [==============================] - 197s 86ms/step - loss: 0.5143 - sensitivity: 0.7311 - specificity: 0.8066 - acc: 0.7656 - val_loss: 0.5498 - val_sensitivity: 0.8072 - val_specificity: 0.0833 - val_acc: 0.6108\n"
     ]
    }
   ],
   "source": [
    "params = { 'blocks': 5, 'dropout': 0, 'regularization': 0, 'kernel_size': 16, 'reduceLR': True}\n",
    "classifier = MODEL(input_shape=np.shape(xtrain)[1], blocks = params['blocks'], dropout=params['dropout'], regularization=params['regularization'])\n",
    "callbacks = [ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.001)]\n",
    "\n",
    "# class_weights = class_weight.compute_class_weight('balanced',\n",
    "#                                                   np.unique(ytrain),\n",
    "#                                                   ytrain)\n",
    "history = classifier.fit(xtrain,\n",
    "                         ytrain,\n",
    "                         batch_size = BATCH_SIZE,\n",
    "                         epochs = EPOCHS,\n",
    "                         validation_split=0.2,\n",
    "#                          class_weight = class_weights,\n",
    "                         callbacks = callbacks\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpred = classifier.predict_classes(xtrain)\n",
    "testpred = classifier.predict_classes(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(pred, real):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    ConfusionMatrix= pd.DataFrame(confusion_matrix(pred,real), columns=['True','False'], index=['True','False'])\n",
    "    print(ConfusionMatrix)\n",
    "    print('----------------')\n",
    "    print('Precision:', ConfusionMatrix.iloc[0,0] / (ConfusionMatrix.iloc[0,0] + ConfusionMatrix.iloc[1,0]))\n",
    "    print('Recall:', ConfusionMatrix.iloc[0,0] / (ConfusionMatrix.iloc[0,0] + ConfusionMatrix.iloc[1,1]))\n",
    "    print('Accuracy:', (ConfusionMatrix.iloc[0,0] + ConfusionMatrix.iloc[1,1]) / (ConfusionMatrix.iloc[0,0] + ConfusionMatrix.iloc[1,0] + ConfusionMatrix.iloc[0,1] + ConfusionMatrix.iloc[1,1]))\n",
    "    print('AUC:', roc_auc_score(pred,real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric([t[0] for t in testpred], ytest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrate with randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "col = trainset.drop(['peak','annotation','strip','stripPVC','id','lead'],axis=1).columns.values\n",
    "scale = preprocessing.StandardScaler()\n",
    "scale.fit(trainset.drop(['peak','annotation','strip','stripPVC','id','lead'], axis=1))\n",
    "trainset['cnnProb'] = trainpred\n",
    "testset['cnnProb'] = testpred\n",
    "n_trainset = pd.DataFrame(scale.transform(trainset.drop(['peak','annotation','strip','stripPVC','id','lead'], axis=1)),columns=col)\n",
    "n_testset = pd.DataFrame(scale.transform(testset.drop(['peak','annotation','strip','stripPVC','id','lead'], axis=1)),columns=col)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
