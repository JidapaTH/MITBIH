{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Model\n",
    "\n",
    "Use 1D-KNN\n",
    "\n",
    "Note: This code have to be run after preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras import regularizers\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.utils import class_weight\n",
    "from keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = pickle.load(open(\"./trainset.p\",'rb'))\n",
    "testset = pickle.load(open(\"./testset.p\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R_interval_mean</th>\n",
       "      <th>R_interval_sd</th>\n",
       "      <th>age</th>\n",
       "      <th>annotation</th>\n",
       "      <th>gender</th>\n",
       "      <th>id</th>\n",
       "      <th>lead</th>\n",
       "      <th>p2p_mean</th>\n",
       "      <th>p2p_std</th>\n",
       "      <th>peak</th>\n",
       "      <th>strip</th>\n",
       "      <th>p2p_diff_form_norm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stripPVC</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>937</td>\n",
       "      <td>937</td>\n",
       "      <td>937</td>\n",
       "      <td>937</td>\n",
       "      <td>937</td>\n",
       "      <td>937</td>\n",
       "      <td>937</td>\n",
       "      <td>937</td>\n",
       "      <td>937</td>\n",
       "      <td>937</td>\n",
       "      <td>937</td>\n",
       "      <td>937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>674</td>\n",
       "      <td>674</td>\n",
       "      <td>674</td>\n",
       "      <td>674</td>\n",
       "      <td>674</td>\n",
       "      <td>674</td>\n",
       "      <td>674</td>\n",
       "      <td>674</td>\n",
       "      <td>674</td>\n",
       "      <td>674</td>\n",
       "      <td>674</td>\n",
       "      <td>674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          R_interval_mean  R_interval_sd  age  annotation  gender   id  lead  \\\n",
       "stripPVC                                                                       \n",
       "False                 937            937  937         937     937  937   937   \n",
       "True                  674            674  674         674     674  674   674   \n",
       "\n",
       "          p2p_mean  p2p_std  peak  strip  p2p_diff_form_norm  \n",
       "stripPVC                                                      \n",
       "False          937      937   937    937                 937  \n",
       "True           674      674   674    674                 674  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USE_KFOLD = True\n",
    "testset.groupby('stripPVC').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = trainset['strip']\n",
    "ytrain = [1 if i == True else 0 for i in trainset['stripPVC']]\n",
    "xtest = testset['strip']\n",
    "ytest = [1 if i == True else 0  for i in testset['stripPVC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2864, 3600, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert\n",
    "\n",
    "xtrain = np.stack(xtrain)\n",
    "xtrain = np.reshape(xtrain, (xtrain.shape[0], xtrain.shape[1], 1))\n",
    "xtest = np.stack(xtest)\n",
    "xtest = np.reshape(xtest, (xtest.shape[0], xtest.shape[1], 1))\n",
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())\n",
    "def CNN_2(input_shape, blocks = 2, dropout = 0, regularization = 0.001, kernel_size = 16):  \n",
    "    classifier = Sequential()\n",
    "    classifier.add(Conv1D(filters = 100, kernel_size = kernel_size, activation = 'relu', input_shape = (input_shape, 1)))\n",
    "    classifier.add(Dropout(dropout))\n",
    "    classifier.add(Conv1D(filters = 160, kernel_size = kernel_size, activation = 'relu'))\n",
    "    classifier.add(MaxPooling1D(pool_size = 2))\n",
    "    classifier.add(LeakyReLU())\n",
    "    classifier.add(LeakyReLU())\n",
    "    classifier.add(Dropout(dropout))\n",
    "    classifier.add(GlobalAveragePooling1D())\n",
    "    classifier.add((Dense(1, activation='sigmoid')))\n",
    "   \n",
    "    \n",
    " \n",
    "    \n",
    "    classifier.compile(optimizer = 'adam',\n",
    "                       loss = 'binary_crossentropy',\n",
    "                       metrics = [sensitivity,specificity,'accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NUMBER = '1'\n",
    "MODEL = CNN_2\n",
    "N_SPLITS = 5\n",
    "BATCH_SIZE = 10\n",
    "EPOCHS = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2291 samples, validate on 573 samples\n",
      "Epoch 1/10\n",
      "2291/2291 [==============================] - 194s 85ms/step - loss: 0.6782 - sensitivity: 0.9489 - specificity: 0.0244 - acc: 0.5155 - val_loss: 0.5896 - val_sensitivity: 0.9651 - val_specificity: 0.0000e+00 - val_acc: 0.7068\n",
      "Epoch 2/10\n",
      "2291/2291 [==============================] - 189s 82ms/step - loss: 0.6601 - sensitivity: 0.8829 - specificity: 0.1786 - acc: 0.5561 - val_loss: 0.5706 - val_sensitivity: 0.9616 - val_specificity: 0.0102 - val_acc: 0.7103\n",
      "Epoch 3/10\n",
      "2291/2291 [==============================] - 218s 95ms/step - loss: 0.6429 - sensitivity: 0.7727 - specificity: 0.4099 - acc: 0.5976 - val_loss: 0.4755 - val_sensitivity: 0.9651 - val_specificity: 0.0475 - val_acc: 0.7452\n",
      "Epoch 4/10\n",
      "2291/2291 [==============================] - 215s 94ms/step - loss: 0.6228 - sensitivity: 0.6891 - specificity: 0.6212 - acc: 0.6560 - val_loss: 0.5700 - val_sensitivity: 0.7358 - val_specificity: 0.1516 - val_acc: 0.5881\n",
      "Epoch 5/10\n",
      "2291/2291 [==============================] - 210s 92ms/step - loss: 0.5883 - sensitivity: 0.6892 - specificity: 0.7203 - acc: 0.7067 - val_loss: 0.6231 - val_sensitivity: 0.5391 - val_specificity: 0.4837 - val_acc: 0.6073\n",
      "Epoch 6/10\n",
      "2291/2291 [==============================] - 227s 99ms/step - loss: 0.5759 - sensitivity: 0.6654 - specificity: 0.7996 - acc: 0.7206 - val_loss: 0.6765 - val_sensitivity: 0.5622 - val_specificity: 0.4623 - val_acc: 0.6056\n",
      "Epoch 7/10\n",
      "2291/2291 [==============================] - 225s 98ms/step - loss: 0.5497 - sensitivity: 0.6875 - specificity: 0.7946 - acc: 0.7429 - val_loss: 0.5778 - val_sensitivity: 0.6738 - val_specificity: 0.2955 - val_acc: 0.6091\n",
      "Epoch 8/10\n",
      "2291/2291 [==============================] - 217s 95ms/step - loss: 0.5247 - sensitivity: 0.7151 - specificity: 0.8262 - acc: 0.7634 - val_loss: 0.5777 - val_sensitivity: 0.6972 - val_specificity: 0.1538 - val_acc: 0.5602\n",
      "Epoch 9/10\n",
      "2291/2291 [==============================] - 5175s 2s/step - loss: 0.5086 - sensitivity: 0.7296 - specificity: 0.8242 - acc: 0.7735 - val_loss: 0.7651 - val_sensitivity: 0.6311 - val_specificity: 0.1584 - val_acc: 0.4852\n",
      "Epoch 10/10\n",
      "2291/2291 [==============================] - 230s 100ms/step - loss: 0.5029 - sensitivity: 0.7238 - specificity: 0.8391 - acc: 0.7765 - val_loss: 0.9132 - val_sensitivity: 0.3986 - val_specificity: 0.4788 - val_acc: 0.4834\n"
     ]
    }
   ],
   "source": [
    "params = { 'blocks': 5, 'dropout': 0, 'regularization': 0, 'kernel_size': 16, 'reduceLR': True}\n",
    "classifier = MODEL(input_shape=np.shape(xtrain)[1], blocks = params['blocks'], dropout=params['dropout'], regularization=params['regularization'])\n",
    "callbacks = [ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.001)]\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                  np.unique(ytrain),\n",
    "                                                  ytrain)\n",
    "history = classifier.fit(xtrain,\n",
    "                         ytrain,\n",
    "                         batch_size = BATCH_SIZE,\n",
    "                         epochs = EPOCHS,\n",
    "                         validation_split=0.2,\n",
    "                         class_weight = class_weights,\n",
    "                         callbacks = callbacks\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpred = classifier.predict_classes(xtrain)\n",
    "testpred = classifier.predict_classes(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(pred, real):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    ConfusionMatrix= pd.DataFrame(confusion_matrix(pred,real), columns=['True','False'], index=['True','False'])\n",
    "    print(ConfusionMatrix)\n",
    "    print('----------------')\n",
    "    print('Precision:', ConfusionMatrix.iloc[0,0] / (ConfusionMatrix.iloc[0,0] + ConfusionMatrix.iloc[1,0]))\n",
    "    print('Recall:', ConfusionMatrix.iloc[0,0] / (ConfusionMatrix.iloc[0,0] + ConfusionMatrix.iloc[1,1]))\n",
    "    print('Accuracy:', (ConfusionMatrix.iloc[0,0] + ConfusionMatrix.iloc[1,1]) / (ConfusionMatrix.iloc[0,0] + ConfusionMatrix.iloc[1,0] + ConfusionMatrix.iloc[0,1] + ConfusionMatrix.iloc[1,1]))\n",
    "    print('AUC:', roc_auc_score(pred,real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric([t[0] for t in testpred], ytest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrate with randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "col = trainset.drop(['peak','annotation','strip','stripPVC','id','lead'],axis=1).columns.values\n",
    "scale = preprocessing.StandardScaler()\n",
    "scale.fit(trainset.drop(['peak','annotation','strip','stripPVC','id','lead'], axis=1))\n",
    "trainset['cnnProb'] = trainpred\n",
    "testset['cnnProb'] = testpred\n",
    "n_trainset = pd.DataFrame(scale.transform(trainset.drop(['peak','annotation','strip','stripPVC','id','lead'], axis=1)),columns=col)\n",
    "n_testset = pd.DataFrame(scale.transform(testset.drop(['peak','annotation','strip','stripPVC','id','lead'], axis=1)),columns=col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
